{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_muslim = pd.read_csv(\"toxicbias_train.csv\")\n",
    "df_muslim = df_muslim[df_muslim['rationale'] == 'prejudice against muslims']\n",
    "df_neutral = pd.read_csv(\"toxicbias_train.csv\")\n",
    "df_neutral = df_neutral[df_neutral['bias'] == 'neutral'].sample(df_muslim.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from src.Helpers import *\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def standardise_results(results):\n",
    "    label_mapping = {'contradiction': results['contradiction'],\n",
    "                     'neutral': results['neutral'],\n",
    "                     'entailment': results['entailment']}\n",
    "    return label_mapping\n",
    "\n",
    "\n",
    "def convert_probabilities(probabilities, label_mapping):\n",
    "    probabilities_list = probabilities.tolist()[0]  # Convert the tensor to a list and extract the first (and only) batch\n",
    "    return {name: round(float(pred) * 100, 1) for pred, name in zip(probabilities_list, label_mapping)}\n",
    "\n",
    "\n",
    "\n",
    "def get_random_samples(csv_filename, num_samples):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    random_samples = df.sample(n=num_samples)\n",
    "    return random_samples\n",
    "\n",
    "\n",
    "def benchmark_test(premise, hypothesis, model, num_runs):\n",
    "    # Setup device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    results = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _, _ = model(premise, hypothesis)\n",
    "        execution_time = time.time() - start_time\n",
    "        results.append(execution_time)\n",
    "\n",
    "    avg_execution_time = sum(results) / len(results)\n",
    "    return device, avg_execution_time\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "premises_bias = df_muslim['comment_text'].values\n",
    "premises_bias = [str(p) for p in premises_bias]\n",
    "\n",
    "premises_neutral = df_neutral['comment_text'].values\n",
    "premises_neutral = [str(p) for p in premises_neutral]\n",
    "\n",
    "hypotheses = [\n",
    "  'The use of violence is encouraged or desired against a religion.',\n",
    "  'A religion should be discriminated against.',\n",
    "  'Members of a religion should be excluded and marginalized.',\n",
    "  'Members of a religion should remain in their respective countries.',\n",
    "  'Members of a religion are compared to animals.',\n",
    "  'A religion or members of a religion are compared to devils or demons.',\n",
    "  'The integration of a religion should be avoided in a country or society.',\n",
    "  'A religion or members of a religion are stupid.',\n",
    "  'A religion is inferior when compared to another religion.',\n",
    "  'Religious practices of a particular faith should be restricted or banned in public spaces.',\n",
    "  'Religious attire or symbols should be prohibited.',\n",
    "  'A religion promotes violence or intolerance.',\n",
    "  'Members of a religion are a threat.',\n",
    "  'Members of a religion are not trustworthy or loyal.'\n",
    " ]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_colwidth', 500)  # Display full text in columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Assuming you have already defined DEVICE and the convert_probabilities and standardise_results functions.\n",
    "\n",
    "def bart_nli_nested(premises, hypotheses):\n",
    "    model_name = 'facebook/bart-large-mnli'\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    # Convert scalar inputs to lists\n",
    "    if not isinstance(premises, (list, tuple)):\n",
    "        premises = [premises]\n",
    "    if not isinstance(hypotheses, (list, tuple)):\n",
    "        hypotheses = [hypotheses]\n",
    "\n",
    "    num_premises = len(premises)\n",
    "    num_hypotheses = len(hypotheses)\n",
    "    results = {}\n",
    "\n",
    "    for i in range(num_premises):\n",
    "        labels = []\n",
    "        probabilities_list = []\n",
    "\n",
    "        for j in range(num_hypotheses):\n",
    "            # Tokenize the input pair\n",
    "            inputs = tokenizer(premises[i], hypotheses[j], return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "            # Run the input through the model\n",
    "            logits = model(**inputs.to(DEVICE)).logits\n",
    "\n",
    "            # Get probabilities and labels for the input\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            label_mapping = ['contradiction', 'neutral', 'entailment']\n",
    "            label = label_mapping[probabilities.argmax(dim=1)]\n",
    "\n",
    "            probabilities = convert_probabilities(probabilities, label_mapping)\n",
    "\n",
    "            labels.append(label)\n",
    "            probabilities_list.append(standardise_results(probabilities))\n",
    "\n",
    "        results[premises[i]] = (labels, probabilities_list)\n",
    "\n",
    "    return results\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df = df_muslim.copy()\n",
    "results = bart_nli_nested(premises_bias, hypotheses)\n",
    "\n",
    "# Process the results separately and add them to the dataframe\n",
    "labels_column = []\n",
    "probabilities_column = []\n",
    "\n",
    "for premise in df['comment_text']:\n",
    "    if premise in results:\n",
    "        labels, probabilities = results[premise]\n",
    "    else:\n",
    "        labels, probabilities = None, None\n",
    "    labels_column.append(labels)\n",
    "    probabilities_column.append(probabilities)\n",
    "\n",
    "df['labels'] = labels_column\n",
    "df['probabilities'] = probabilities_column\n",
    "\n",
    "filtered_df = df.dropna(subset=['labels'])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Function to check if 'entailment' is present in a row\n",
    "def has_entailment(row):\n",
    "    return 'entailment' in row\n",
    "\n",
    "# Apply the function to each row in the 'results' column\n",
    "filtered_df['has_entailment'] = filtered_df['labels'].apply(has_entailment)\n",
    "\n",
    "# Count the number of rows with 'entailment' and the ones without\n",
    "num_rows_with_entailment = filtered_df['has_entailment'].sum()\n",
    "num_rows_without_entailment = filtered_df.shape[0] - num_rows_with_entailment\n",
    "\n",
    "print(\"Rows with 'entailment':\", num_rows_with_entailment)\n",
    "print(\"Rows without 'entailment':\", num_rows_without_entailment)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rows with 'entailment': 16\n",
      "Rows without 'entailment': 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/yy/fwc73zl141q0zj_v307n1l9w0000gn/T/ipykernel_16477/3429989658.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['has_entailment'] = filtered_df['labels'].apply(has_entailment)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df_neutral.copy()\n",
    "results = bart_nli_nested(premises_neutral, hypotheses)\n",
    "\n",
    "# Process the results separately and add them to the dataframe\n",
    "labels_column = []\n",
    "probabilities_column = []\n",
    "\n",
    "for premise in df['comment_text']:\n",
    "    if premise in results:\n",
    "        labels, probabilities = results[premise]\n",
    "    else:\n",
    "        labels, probabilities = None, None\n",
    "    labels_column.append(labels)\n",
    "    probabilities_column.append(probabilities)\n",
    "\n",
    "df['labels'] = labels_column\n",
    "df['probabilities'] = probabilities_column\n",
    "\n",
    "filtered_df_neutral = df.dropna(subset=['labels'])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to check if 'entailment' is present in a row\n",
    "def has_entailment(row):\n",
    "    return 'entailment' in row\n",
    "\n",
    "# Apply the function to each row in the 'results' column\n",
    "filtered_df_neutral['has_entailment'] = filtered_df_neutral['labels'].apply(has_entailment)\n",
    "\n",
    "# Count the number of rows with 'entailment' and the ones without\n",
    "num_rows_with_entailment = filtered_df_neutral['has_entailment'].sum()\n",
    "num_rows_without_entailment = filtered_df_neutral.shape[0] - num_rows_with_entailment\n",
    "\n",
    "print(\"Rows with 'entailment':\", num_rows_with_entailment)\n",
    "print(\"Rows without 'entailment':\", num_rows_without_entailment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "bias_df = pd.DataFrame(filtered_df)\n",
    "neutral_df = pd.DataFrame(filtered_df_neutral)\n",
    "\n",
    "# Define the criterion for the biased DataFrame (all results should be 'entailment')\n",
    "def is_correct_bias(row):\n",
    "    return any(label == 'entailment' for label in row)\n",
    "\n",
    "# Define the criterion for the neutral DataFrame (all results should be 'contradiction' or 'neutral')\n",
    "def is_correct_neutral(row):\n",
    "    return all(label != 'entailment' for label in row)\n",
    "\n",
    "# Apply the functions to create binary arrays indicating correctness in both DataFrames\n",
    "bias_df['is_correct'] = bias_df['labels'].apply(is_correct_bias)\n",
    "neutral_df['is_correct'] = neutral_df['labels'].apply(is_correct_neutral)\n",
    "\n",
    "# Combine both DataFrames\n",
    "combined_df = pd.concat([bias_df, neutral_df], ignore_index=True)\n",
    "combined_df['predicted'] = True\n",
    "\n",
    "# Calculate the F1 score for the combined DataFrame\n",
    "f1 = f1_score(combined_df['is_correct'], combined_df['predicted'], average='weighted')\n",
    "\n",
    "print(\"Combined F1 score:\", f1)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Assuming you have already defined DEVICE and the convert_probabilities and standardise_results functions.\n",
    "\n",
    "def bart_nli_batched(premises, hypotheses):\n",
    "    model_name = 'facebook/bart-large-mnli'\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    # Convert scalar inputs to lists\n",
    "    if not isinstance(premises, (list, tuple)):\n",
    "        premises = [premises]\n",
    "    if not isinstance(hypotheses, (list, tuple)):\n",
    "        hypotheses = [hypotheses]\n",
    "\n",
    "    # Tokenize all input pairs together\n",
    "    inputs = tokenizer(premises, hypotheses, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs.to(DEVICE)\n",
    "\n",
    "    # Run the input through the model\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "    \n",
    "    return logits\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Assuming you have already defined DEVICE and the convert_probabilities and standardise_results functions.\n",
    "\n",
    "def bart_nli_batched(premises, hypotheses):\n",
    "    model_name = 'facebook/bart-large-mnli'\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    # Convert scalar inputs to lists\n",
    "    if not isinstance(premises, (list, tuple)):\n",
    "        premises = [premises]\n",
    "    if not isinstance(hypotheses, (list, tuple)):\n",
    "        hypotheses = [hypotheses]\n",
    "\n",
    "    num_premises = len(premises)\n",
    "    num_hypotheses = len(hypotheses)\n",
    "    results = {}\n",
    "\n",
    "    for i in range(num_premises):\n",
    "        labels = []\n",
    "        probabilities_list = []\n",
    "\n",
    "        print([premises[i]] * num_hypotheses)\n",
    "        # Tokenize the input pair\n",
    "        inputs = tokenizer([premises[i]] * num_hypotheses, hypotheses, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "        # Run the input through the model\n",
    "        logits = model(**inputs.to(DEVICE)).logits\n",
    "\n",
    "        # Get probabilities and labels for the input\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        label_mapping = ['contradiction', 'neutral', 'entailment']\n",
    "        label = label_mapping[probabilities.argmax(dim=1)]\n",
    "\n",
    "        labels.append(label)\n",
    "        probabilities_list.append((probabilities))\n",
    "\n",
    "        results[premises[i]] = (labels, probabilities_list)\n",
    "\n",
    "    return results\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "bart_nli_batched(premises, hypotheses)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'This whole tragedy is the face and body and physical manifestation of fundamental Islam.  Striving to conquer subdue and to bring under control.  Do not blame the world.  Blame fundamental Islam for this tragedy.': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'contradiction']],\n",
       "  [tensor([[0.0231, 0.2139, 0.7630],\n",
       "           [0.9727, 0.0257, 0.0016],\n",
       "           [0.9570, 0.0402, 0.0028],\n",
       "           [0.9869, 0.0107, 0.0023],\n",
       "           [0.8176, 0.1689, 0.0134],\n",
       "           [0.4699, 0.4351, 0.0950],\n",
       "           [0.7749, 0.2211, 0.0039],\n",
       "           [0.6829, 0.3095, 0.0076],\n",
       "           [0.8244, 0.1235, 0.0521],\n",
       "           [0.1786, 0.8131, 0.0083],\n",
       "           [0.6715, 0.3251, 0.0034],\n",
       "           [0.0050, 0.0722, 0.9228],\n",
       "           [0.0342, 0.3565, 0.6094],\n",
       "           [0.9035, 0.0944, 0.0021]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Another Muslim commits a terrorist act and democrats will once again blame the NRA. NYC New Jersey Minnesota Orlando San Bernardino. Get it yet?': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[0.0712, 0.2233, 0.7055],\n",
       "           [0.8935, 0.1037, 0.0028],\n",
       "           [0.7773, 0.2201, 0.0026],\n",
       "           [0.5433, 0.4545, 0.0022],\n",
       "           [0.7367, 0.2335, 0.0298],\n",
       "           [0.5468, 0.4229, 0.0303],\n",
       "           [0.2814, 0.7162, 0.0024],\n",
       "           [0.5928, 0.3952, 0.0120],\n",
       "           [0.6214, 0.2968, 0.0818],\n",
       "           [0.0497, 0.9490, 0.0013],\n",
       "           [0.2215, 0.7766, 0.0018],\n",
       "           [0.0186, 0.2386, 0.7428],\n",
       "           [0.0063, 0.2435, 0.7503],\n",
       "           [0.2103, 0.7713, 0.0184]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'AntiMuslim protesters shout hateful rhetoric.  Muslim fundamentalist nutjobs murder innocent people.  Not quite the same thing is it?': ([['entailment',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[0.2182, 0.3083, 0.4735],\n",
       "           [0.7419, 0.2409, 0.0172],\n",
       "           [0.3745, 0.6054, 0.0201],\n",
       "           [0.4866, 0.5011, 0.0123],\n",
       "           [0.1336, 0.8400, 0.0264],\n",
       "           [0.1073, 0.7912, 0.1014],\n",
       "           [0.5991, 0.3981, 0.0028],\n",
       "           [0.7386, 0.2503, 0.0111],\n",
       "           [0.3217, 0.6093, 0.0690],\n",
       "           [0.2735, 0.7139, 0.0126],\n",
       "           [0.2731, 0.7249, 0.0020],\n",
       "           [0.2080, 0.3119, 0.4801],\n",
       "           [0.0188, 0.3134, 0.6678],\n",
       "           [0.4038, 0.5660, 0.0302]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'I learned that those who are both religious and righteous are some of the most dangerous people on this earth.    Yes radical Islam is very dangerous.  NeverHillary': ([['neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[1.3774e-01, 7.3570e-01, 1.2655e-01],\n",
       "           [9.4148e-01, 5.7770e-02, 7.4929e-04],\n",
       "           [2.7121e-01, 7.1979e-01, 9.0016e-03],\n",
       "           [2.2592e-01, 7.5719e-01, 1.6892e-02],\n",
       "           [7.1938e-01, 2.5613e-01, 2.4491e-02],\n",
       "           [6.1175e-01, 3.6107e-01, 2.7182e-02],\n",
       "           [7.4281e-03, 9.6138e-01, 3.1190e-02],\n",
       "           [9.3290e-01, 6.1812e-02, 5.2845e-03],\n",
       "           [5.9373e-01, 3.4644e-01, 5.9836e-02],\n",
       "           [1.4083e-02, 9.8280e-01, 3.1160e-03],\n",
       "           [3.3134e-02, 9.5826e-01, 8.6083e-03],\n",
       "           [5.5001e-02, 7.4380e-01, 2.0120e-01],\n",
       "           [7.3614e-03, 1.3286e-01, 8.5978e-01],\n",
       "           [3.6647e-01, 5.1399e-01, 1.1954e-01]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Wow how times have changed All hail the muslim. It wasnt so very long ago that Christians were told to remove all crosses from government properties in Hawaii and even some privately owned churches were heartily challenged. Now we have foreign born muslims on the front page and their right to be is heavily protected. Go figure.': ([['contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction']],\n",
       "  [tensor([[7.8619e-01, 2.1036e-01, 3.4475e-03],\n",
       "           [9.3764e-01, 6.0750e-02, 1.6102e-03],\n",
       "           [9.9103e-01, 8.6732e-03, 2.9881e-04],\n",
       "           [4.7836e-01, 4.9864e-01, 2.3004e-02],\n",
       "           [9.5978e-01, 3.4347e-02, 5.8773e-03],\n",
       "           [9.3539e-01, 5.2625e-02, 1.1987e-02],\n",
       "           [8.9019e-01, 1.0958e-01, 2.2572e-04],\n",
       "           [7.0109e-01, 2.9318e-01, 5.7293e-03],\n",
       "           [8.6099e-01, 1.0854e-01, 3.0478e-02],\n",
       "           [7.2287e-01, 2.7014e-01, 6.9953e-03],\n",
       "           [5.7451e-01, 4.1904e-01, 6.4570e-03],\n",
       "           [4.5419e-01, 5.0880e-01, 3.7010e-02],\n",
       "           [7.1771e-01, 1.8869e-01, 9.3600e-02],\n",
       "           [9.0593e-01, 9.3128e-02, 9.4101e-04]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'PRips This sounds like a muslim trying to sound intelligent. Read the post again.': ([['neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral']],\n",
       "  [tensor([[0.3617, 0.5887, 0.0496],\n",
       "           [0.8791, 0.1190, 0.0019],\n",
       "           [0.8526, 0.1458, 0.0016],\n",
       "           [0.5013, 0.4949, 0.0038],\n",
       "           [0.7699, 0.2059, 0.0242],\n",
       "           [0.6463, 0.3324, 0.0213],\n",
       "           [0.1015, 0.8965, 0.0021],\n",
       "           [0.7317, 0.2565, 0.0118],\n",
       "           [0.2878, 0.6539, 0.0583],\n",
       "           [0.1743, 0.8194, 0.0063],\n",
       "           [0.3816, 0.6150, 0.0033],\n",
       "           [0.4673, 0.5235, 0.0091],\n",
       "           [0.0689, 0.8842, 0.0469],\n",
       "           [0.4887, 0.5007, 0.0106]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'I got your point NeoNazi GOOD Muslim BAD...MAGA': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[0.0208, 0.4368, 0.5424],\n",
       "           [0.8101, 0.1804, 0.0095],\n",
       "           [0.8582, 0.1398, 0.0021],\n",
       "           [0.4106, 0.5871, 0.0023],\n",
       "           [0.4969, 0.3491, 0.1540],\n",
       "           [0.0806, 0.3188, 0.6006],\n",
       "           [0.3111, 0.6867, 0.0023],\n",
       "           [0.7903, 0.1964, 0.0132],\n",
       "           [0.1328, 0.3814, 0.4858],\n",
       "           [0.1802, 0.8182, 0.0016],\n",
       "           [0.4916, 0.5060, 0.0024],\n",
       "           [0.0267, 0.7696, 0.2037],\n",
       "           [0.0141, 0.3673, 0.6186],\n",
       "           [0.3132, 0.6410, 0.0458]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'He was sick with hatred of white people who were his victims and should have never been aloud in this country cant you see hes a middle eastern muslim.': ([['neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'contradiction']],\n",
       "  [tensor([[0.3272, 0.3391, 0.3338],\n",
       "           [0.8200, 0.1378, 0.0422],\n",
       "           [0.3505, 0.5178, 0.1317],\n",
       "           [0.0093, 0.1514, 0.8393],\n",
       "           [0.6448, 0.3317, 0.0235],\n",
       "           [0.4650, 0.5001, 0.0349],\n",
       "           [0.0385, 0.5932, 0.3684],\n",
       "           [0.6259, 0.3671, 0.0070],\n",
       "           [0.5754, 0.3799, 0.0447],\n",
       "           [0.0344, 0.3287, 0.6369],\n",
       "           [0.0273, 0.6984, 0.2743],\n",
       "           [0.0129, 0.4207, 0.5664],\n",
       "           [0.0311, 0.5517, 0.4172],\n",
       "           [0.5207, 0.4761, 0.0032]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Since all do it...none are guilty or all guilty to the same degree?  Maybe a couple of nuclear bombs should be dropped on a Muslim country.': ([['entailment',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[1.5758e-02, 1.1867e-01, 8.6557e-01],\n",
       "           [3.2945e-02, 1.8419e-01, 7.8286e-01],\n",
       "           [1.2414e-01, 5.2410e-01, 3.5176e-01],\n",
       "           [9.9909e-01, 7.7915e-04, 1.3528e-04],\n",
       "           [4.8683e-01, 3.1521e-01, 1.9796e-01],\n",
       "           [6.5868e-01, 3.0073e-01, 4.0583e-02],\n",
       "           [8.3376e-01, 1.5764e-01, 8.5984e-03],\n",
       "           [7.1584e-01, 2.7285e-01, 1.1312e-02],\n",
       "           [7.3766e-01, 1.5750e-01, 1.0484e-01],\n",
       "           [2.8798e-01, 6.1750e-01, 9.4527e-02],\n",
       "           [2.2110e-01, 7.6929e-01, 9.6111e-03],\n",
       "           [1.8307e-02, 6.6822e-01, 3.1347e-01],\n",
       "           [1.2307e-02, 2.5533e-01, 7.3236e-01],\n",
       "           [4.3812e-01, 5.1056e-01, 5.1314e-02]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Its not absurd to say a philosophy which calls for the death or enslavement of everyone else except Muslims has an influence. Islam is problematic as a belief system. All the Abrahamic religions are nonsense. STOP SPREADING LIES I blame the media for giving credence to such nonsense supernatural garbage clearly not real.': ([['entailment',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[3.5175e-02, 7.0845e-02, 8.9398e-01],\n",
       "           [8.8264e-01, 1.0381e-01, 1.3549e-02],\n",
       "           [2.9758e-01, 6.1597e-01, 8.6451e-02],\n",
       "           [3.5099e-01, 6.2050e-01, 2.8505e-02],\n",
       "           [6.9134e-01, 2.8604e-01, 2.2621e-02],\n",
       "           [2.2559e-01, 6.3671e-01, 1.3770e-01],\n",
       "           [1.7273e-02, 9.7834e-01, 4.3864e-03],\n",
       "           [3.7893e-01, 5.4298e-01, 7.8089e-02],\n",
       "           [4.2909e-01, 2.3769e-01, 3.3322e-01],\n",
       "           [7.4884e-03, 9.8592e-01, 6.5961e-03],\n",
       "           [4.6948e-02, 9.4766e-01, 5.3891e-03],\n",
       "           [9.4163e-04, 2.4659e-02, 9.7440e-01],\n",
       "           [8.3514e-02, 4.4914e-01, 4.6735e-01],\n",
       "           [1.2533e-01, 8.5746e-01, 1.7214e-02]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Islam is a pernicious malignancy. Moses is the true prophet. I would prefer not being under Islamic compulsion. There is no redemption under compulsion. If youre forced to pray 500 times a day it has no true meaning because it was an act of submission not voluntary. Little wonder they rebel and see no future for themselves. They should ask Jesus and Moses to redeem them.': ([['neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'contradiction']],\n",
       "  [tensor([[0.1805, 0.5855, 0.2340],\n",
       "           [0.9020, 0.0841, 0.0139],\n",
       "           [0.9157, 0.0707, 0.0135],\n",
       "           [0.8599, 0.0727, 0.0674],\n",
       "           [0.6960, 0.2756, 0.0285],\n",
       "           [0.1526, 0.7047, 0.1427],\n",
       "           [0.0295, 0.8925, 0.0780],\n",
       "           [0.6426, 0.3350, 0.0224],\n",
       "           [0.2044, 0.2067, 0.5889],\n",
       "           [0.0308, 0.9380, 0.0311],\n",
       "           [0.0598, 0.9315, 0.0088],\n",
       "           [0.0199, 0.1907, 0.7894],\n",
       "           [0.0089, 0.1819, 0.8092],\n",
       "           [0.4651, 0.4479, 0.0870]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'So basically it will now be a crime to insult Prophet Mohammed. Canada joins the ranks of Islam the most backwards society on earth.': ([['contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction']],\n",
       "  [tensor([[0.8347, 0.1331, 0.0321],\n",
       "           [0.9464, 0.0452, 0.0085],\n",
       "           [0.7866, 0.1956, 0.0179],\n",
       "           [0.5644, 0.4210, 0.0146],\n",
       "           [0.7440, 0.2227, 0.0333],\n",
       "           [0.8647, 0.1218, 0.0135],\n",
       "           [0.1937, 0.7851, 0.0212],\n",
       "           [0.5451, 0.4073, 0.0476],\n",
       "           [0.1558, 0.2458, 0.5984],\n",
       "           [0.2031, 0.7403, 0.0566],\n",
       "           [0.1112, 0.8388, 0.0499],\n",
       "           [0.1413, 0.6470, 0.2117],\n",
       "           [0.1955, 0.4576, 0.3469],\n",
       "           [0.6095, 0.3766, 0.0139]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'The muslims guiding book of beliefs  their constitution is the koran. Read it  dozens of passages urge all muslims to either convert or abuse  kill all who do not subscribe to it. Considering the words in the koran I wonder how any reasonable person could call themselves a muslim. Clearly islam is the enemy of every person in the world including those who call themselves muslims.': ([['entailment',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'neutral']],\n",
       "  [tensor([[5.3872e-04, 1.3934e-02, 9.8553e-01],\n",
       "           [8.0786e-01, 1.6122e-01, 3.0924e-02],\n",
       "           [3.4813e-01, 5.3851e-01, 1.1336e-01],\n",
       "           [7.3689e-01, 2.3692e-01, 2.6192e-02],\n",
       "           [5.1410e-01, 4.3949e-01, 4.6414e-02],\n",
       "           [2.9792e-02, 8.0642e-01, 1.6379e-01],\n",
       "           [6.7285e-02, 9.2610e-01, 6.6182e-03],\n",
       "           [6.4442e-01, 3.4160e-01, 1.3976e-02],\n",
       "           [5.7288e-01, 2.7621e-01, 1.5091e-01],\n",
       "           [1.5124e-01, 8.2644e-01, 2.2314e-02],\n",
       "           [2.5591e-02, 9.6363e-01, 1.0781e-02],\n",
       "           [3.0446e-03, 7.1327e-02, 9.2563e-01],\n",
       "           [9.2193e-03, 2.5301e-01, 7.3777e-01],\n",
       "           [3.2523e-01, 6.0414e-01, 7.0627e-02]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'yes I have seen this and it is not a lie every muslim takes a vow to kill': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral']],\n",
       "  [tensor([[4.7561e-03, 1.2194e-01, 8.7330e-01],\n",
       "           [9.1483e-01, 8.4554e-02, 6.1412e-04],\n",
       "           [7.7060e-01, 2.2796e-01, 1.4406e-03],\n",
       "           [7.9262e-01, 2.0618e-01, 1.1958e-03],\n",
       "           [1.0373e-01, 7.5582e-01, 1.4045e-01],\n",
       "           [2.2660e-01, 6.0714e-01, 1.6625e-01],\n",
       "           [1.2279e-01, 8.7640e-01, 8.1002e-04],\n",
       "           [5.7359e-01, 4.2164e-01, 4.7719e-03],\n",
       "           [6.0499e-01, 3.4199e-01, 5.3018e-02],\n",
       "           [7.3986e-02, 9.2261e-01, 3.3994e-03],\n",
       "           [1.7411e-01, 8.2338e-01, 2.5141e-03],\n",
       "           [2.1540e-03, 1.5683e-01, 8.4101e-01],\n",
       "           [9.9638e-03, 5.8230e-01, 4.0773e-01],\n",
       "           [3.9191e-01, 5.9141e-01, 1.6682e-02]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Just another Middle Eastern mouthpiece meddling where he doesnt belong. Cant even run his own shit hole Country much less anyone elses. Giving Muslims a bad name just what they need': ([['neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral']],\n",
       "  [tensor([[0.3910, 0.5663, 0.0427],\n",
       "           [0.9112, 0.0865, 0.0023],\n",
       "           [0.7442, 0.2472, 0.0086],\n",
       "           [0.0043, 0.5544, 0.4414],\n",
       "           [0.5231, 0.4456, 0.0314],\n",
       "           [0.0375, 0.9492, 0.0134],\n",
       "           [0.0188, 0.9517, 0.0295],\n",
       "           [0.7602, 0.2213, 0.0185],\n",
       "           [0.5278, 0.3637, 0.1085],\n",
       "           [0.1116, 0.8828, 0.0056],\n",
       "           [0.0723, 0.9245, 0.0032],\n",
       "           [0.1408, 0.7887, 0.0705],\n",
       "           [0.0535, 0.4768, 0.4697],\n",
       "           [0.3428, 0.6251, 0.0321]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Here is another good one.  Type in Muslim rape in Google and there are 21M stories about it.  This is their culture all of these stories cant be fake.      URL meatbritainsmuslimrapegangcoverup': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'contradiction']],\n",
       "  [tensor([[3.8282e-02, 1.5008e-01, 8.1164e-01],\n",
       "           [9.6521e-01, 3.4376e-02, 4.1415e-04],\n",
       "           [9.8981e-01, 9.9298e-03, 2.6516e-04],\n",
       "           [9.8245e-01, 1.6939e-02, 6.0994e-04],\n",
       "           [1.7429e-01, 2.3079e-01, 5.9492e-01],\n",
       "           [8.7081e-01, 1.0556e-01, 2.3626e-02],\n",
       "           [9.3424e-01, 6.5515e-02, 2.4436e-04],\n",
       "           [6.3842e-01, 3.4246e-01, 1.9118e-02],\n",
       "           [7.5592e-01, 1.9197e-01, 5.2110e-02],\n",
       "           [3.6423e-01, 6.3386e-01, 1.9094e-03],\n",
       "           [7.1359e-01, 2.8306e-01, 3.3587e-03],\n",
       "           [4.2505e-03, 7.2172e-02, 9.2358e-01],\n",
       "           [9.2908e-02, 7.5480e-01, 1.5229e-01],\n",
       "           [9.2119e-01, 7.7458e-02, 1.3485e-03]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'The worry that Trumps hateful attitude towards Muslims outside the United States will extend to them is quite understandable.': ([['neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'contradiction']],\n",
       "  [tensor([[0.0171, 0.5281, 0.4548],\n",
       "           [0.7853, 0.2059, 0.0088],\n",
       "           [0.6161, 0.3803, 0.0036],\n",
       "           [0.3528, 0.6186, 0.0286],\n",
       "           [0.0406, 0.9539, 0.0055],\n",
       "           [0.0271, 0.9194, 0.0535],\n",
       "           [0.7034, 0.2936, 0.0030],\n",
       "           [0.8972, 0.1006, 0.0022],\n",
       "           [0.6395, 0.3392, 0.0213],\n",
       "           [0.2369, 0.7597, 0.0034],\n",
       "           [0.3703, 0.6258, 0.0039],\n",
       "           [0.1553, 0.6486, 0.1961],\n",
       "           [0.0107, 0.5546, 0.4347],\n",
       "           [0.5878, 0.4035, 0.0086]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Ban Muslim refugees and  I will vote for you': ([['neutral',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral']],\n",
       "  [tensor([[0.1301, 0.4418, 0.4282],\n",
       "           [0.5121, 0.3211, 0.1669],\n",
       "           [0.2141, 0.5331, 0.2528],\n",
       "           [0.0834, 0.2296, 0.6870],\n",
       "           [0.4659, 0.4923, 0.0418],\n",
       "           [0.1446, 0.7421, 0.1133],\n",
       "           [0.0109, 0.3784, 0.6107],\n",
       "           [0.6535, 0.3394, 0.0071],\n",
       "           [0.5913, 0.3252, 0.0835],\n",
       "           [0.0070, 0.3184, 0.6746],\n",
       "           [0.0024, 0.6636, 0.3340],\n",
       "           [0.0296, 0.9538, 0.0166],\n",
       "           [0.0164, 0.6662, 0.3175],\n",
       "           [0.1992, 0.7830, 0.0177]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'Islamic fundamentalists assassinated innocent Christians and others in Europe see Charlie Hebdo.  A Christian fundamentalist assassinated innocent Muslims at a mosque in Quebec.   One murder is one too many. Protectionist policies are good for now.': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'contradiction',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'contradiction']],\n",
       "  [tensor([[1.3540e-01, 1.1842e-01, 7.4618e-01],\n",
       "           [9.8143e-01, 1.7203e-02, 1.3647e-03],\n",
       "           [9.8851e-01, 1.0964e-02, 5.2171e-04],\n",
       "           [9.6819e-01, 3.0780e-02, 1.0282e-03],\n",
       "           [9.3807e-01, 5.0859e-02, 1.1074e-02],\n",
       "           [7.1396e-01, 2.5112e-01, 3.4919e-02],\n",
       "           [7.8734e-01, 2.0916e-01, 3.4987e-03],\n",
       "           [8.7179e-01, 1.2576e-01, 2.4439e-03],\n",
       "           [7.4393e-01, 1.9256e-01, 6.3505e-02],\n",
       "           [4.1362e-01, 5.6923e-01, 1.7154e-02],\n",
       "           [6.0218e-01, 3.9118e-01, 6.6366e-03],\n",
       "           [1.9231e-02, 1.0806e-01, 8.7271e-01],\n",
       "           [1.7025e-02, 2.7984e-01, 7.0314e-01],\n",
       "           [6.2381e-01, 3.6849e-01, 7.6948e-03]], grad_fn=<SoftmaxBackward0>)]),\n",
       " 'The word civilians means nothing to them. They want to kill ALL of the Infidels.   Islam  Death Cult': ([['entailment',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'contradiction',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'neutral',\n",
       "    'entailment',\n",
       "    'entailment',\n",
       "    'contradiction']],\n",
       "  [tensor([[4.4201e-03, 4.5215e-02, 9.5036e-01],\n",
       "           [8.3369e-01, 1.4300e-01, 2.3317e-02],\n",
       "           [6.2478e-01, 3.3229e-01, 4.2935e-02],\n",
       "           [9.7243e-01, 2.6608e-02, 9.5834e-04],\n",
       "           [4.8087e-01, 4.5821e-01, 6.0919e-02],\n",
       "           [1.4564e-01, 5.3429e-01, 3.2006e-01],\n",
       "           [1.1813e-01, 8.8074e-01, 1.1308e-03],\n",
       "           [3.5853e-01, 6.0995e-01, 3.1512e-02],\n",
       "           [3.1724e-01, 4.1815e-01, 2.6461e-01],\n",
       "           [8.2130e-02, 9.0871e-01, 9.1581e-03],\n",
       "           [6.9931e-02, 9.2574e-01, 4.3332e-03],\n",
       "           [7.1208e-04, 4.0162e-02, 9.5913e-01],\n",
       "           [2.5026e-02, 2.3201e-01, 7.4297e-01],\n",
       "           [6.2098e-01, 3.5611e-01, 2.2901e-02]], grad_fn=<SoftmaxBackward0>)])}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}