{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "!pip3 install transformers"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (4.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.9/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "source": [
    "import sys\n",
    "sys.path.append('src/')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "# panda view settings\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_colwidth', 500)  # Display full text in columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "source": [
    "DEVICE = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(DEVICE)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "df = pd.read_csv(\"./data/toxicbias_train.csv\")\n",
    "df_bias = df[df['bias'] == 'bias']\n",
    "df_neutral = df[df['bias'] == 'neutral']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split up dataframe by category"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "# store unique categories\n",
    "unique_categories = set()\n",
    "\n",
    "# Iterate through each entry in the 'category' column\n",
    "for categories in df['category'].str.split(','):\n",
    "    for category in categories:\n",
    "        stripped_category = category.strip()\n",
    "        if stripped_category and stripped_category.lower() != 'none':\n",
    "            unique_categories.add(stripped_category)\n",
    "\n",
    "unique_categories_list = sorted(list(unique_categories))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "categorical_dfs = {category: pd.DataFrame(columns=df.columns) for category in unique_categories_list}\n",
    "\n",
    "# Split categories and add rows to the corresponding dataframes in dictionary\n",
    "def split_categories_and_add_rows(row):\n",
    "    categories = row['category'].split(',')\n",
    "    for category in categories:\n",
    "        category = category.strip()  # Remove leading/trailing spaces\n",
    "        if category in categorical_dfs:\n",
    "            categorical_dfs[category] = categorical_dfs[category].append(row, ignore_index=True)\n",
    "\n",
    "df_bias.apply(split_categories_and_add_rows, axis=1)\n",
    "\n",
    "# Print the shape of each category dataframe\n",
    "for category, category_df in categorical_dfs.items():\n",
    "    print(f\"Dataframe for {category}:\")\n",
    "    print(f\"Shape: {category_df.shape}\")\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataframe for gender:\n",
      "Shape: (293, 6)\n",
      "\n",
      "\n",
      "Dataframe for lgbtq:\n",
      "Shape: (453, 6)\n",
      "\n",
      "\n",
      "Dataframe for political:\n",
      "Shape: (172, 6)\n",
      "\n",
      "\n",
      "Dataframe for race:\n",
      "Shape: (1768, 6)\n",
      "\n",
      "\n",
      "Dataframe for religion:\n",
      "Shape: (1257, 6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split training and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "training_data = {}\n",
    "test_data = {}\n",
    "\n",
    "# Perform the 80-20 split for each category dataframe\n",
    "for category, df in categorical_dfs.items():\n",
    "    train_df, test_df = train_test_split(df, test_size=0.8, random_state=42)\n",
    "    \n",
    "    training_data[category] = train_df\n",
    "    test_data[category] = test_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "source": [
    "for category, train_df in training_data.items():\n",
    "    print('Training data')\n",
    "    print(f\"Dataframe for {category}:\")\n",
    "    print(f\"Shape: {train_df.shape}\")\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data\n",
      "Dataframe for gender:\n",
      "Shape: (58, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for lgbtq:\n",
      "Shape: (90, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for political:\n",
      "Shape: (34, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for race:\n",
      "Shape: (353, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for religion:\n",
      "Shape: (251, 6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "for category, test_df in test_data.items():\n",
    "    print('Test data')\n",
    "    print(f\"Dataframe for {category}:\")\n",
    "    print(f\"Shape: {test_df.shape}\")\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data\n",
      "Dataframe for gender:\n",
      "Shape: (470, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for lgbtq:\n",
      "Shape: (726, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for political:\n",
      "Shape: (276, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for race:\n",
      "Shape: (2282, 6)\n",
      "\n",
      "\n",
      "Training data\n",
      "Dataframe for religion:\n",
      "Shape: (1873, 6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Premises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "hypotheses = {\n",
    "  'gender' : [\n",
    "    'A person belonging to a gender lacks intelligence.',\n",
    "    'A person belonging to a gender is a criminal.',\n",
    "    'A person belonging to a gender is violent.',\n",
    "    'Violence is encouraged against a gender.',\n",
    "    'A person belonging to a gender is abusive.',\n",
    "    'A person belonging to a gender should be blamed.',\n",
    "    'Women make decisions based on emotions.',\n",
    "    'A gender is unable to do some jobs.',\n",
    "    'A gender is unable to do something as well as another gender.',\n",
    "    'A gender should not talk.',\n",
    "    'A person belonging to a gender is compared to an object.',\n",
    "    'A gender should be blamed.',\n",
    "    'A person belonging to a gender has an advantage compared to others.',\n",
    "    'A person belonging to a gender is misogynist.',\n",
    "    'A person belonging to a gender is disliked.',\n",
    "  ],\n",
    "  'lgbtq' : [\n",
    "    'Lgbtq persons are believed to have a condition.',\n",
    "    'Lgbtq should not be part of society.',\n",
    "    'Violence is encouraged against lgbtq persons.',\n",
    "    'Lgbtq persons are compared to animals.',\n",
    "    'Lgbtq persons are believed to have an agenda.',\n",
    "    'Lgbtq persons should be excluded.',\n",
    "    'Lgbtq persons should stay home.',\n",
    "    'Lgbtq persons commit crimes.',\n",
    "    'Lgbtq persons get preferred to other persons.',\n",
    "    'Lgbtq persons are seen as not being normal.', \n",
    "    'Lgbtq persons should not be allowed to marry.', \n",
    "    'Lgbtq persons have a disease.',\n",
    "    'Lgbtq persons are seen as being disgusting.',\n",
    "    'Lgbtq persons are not tolerated or desired.',\n",
    "    'Lgbtq persons are treated differently.'\n",
    "\n",
    "  ],\n",
    "  'political' : [ \n",
    "      'A person belonging to a political group is stupid.',\n",
    "      'A person belonging to a political group is crazy.',\n",
    "      'Things are worse due to a political group.',\n",
    "      'Members of a political group are lgbtq.',\n",
    "      'Members of a political group are hypocritical.',\n",
    "      'Members of a political group dislike a gender or lgbtq.',\n",
    "      'Members of a political group commit crimes.',\n",
    "      'Members of a political group are violent.',\n",
    "      'Members of a political group are hateful.',\n",
    "      'Members of a political group are compared to Nazis.',\n",
    "      'Members of a political group are racist.',\n",
    "      'A person belonging to a political group has a disease.',\n",
    "      'Members of a political group are taking control.',\n",
    "      'Members of a political group prefer minorities.',\n",
    "      'Members of a political group hate their country or race.',\n",
    "  ],\n",
    "  'race' : [\n",
    "    'Members of a race commit crimes.',\n",
    "    'Members of a race are violent.',\n",
    "    'Members of a race are compared to animals.',\n",
    "    'The use of violence is encouraged or desired against a race.',\n",
    "    'Members of a race should remain in their respective countries.',\n",
    "    'The integration of a race should be avoided in a country or society.',\n",
    "    'Members of a race are a threat to others.',\n",
    "    'A race is inferior when compared to another race.',\n",
    "    'A race is preferred to another.',\n",
    "    'Members of a race are stupid.',\n",
    "    'There are too many members of a race.',\n",
    "    'Members of a race should be excluded.',\n",
    "    'Members of a race should go back to their homes.',\n",
    "    'Members of a race are refused.',\n",
    "    'Members of a race are racist.'\n",
    "  ],\n",
    "  'religion' : [\n",
    "    'The use of violence is encouraged or desired against a religion.',\n",
    "    'A religion should be discriminated against.',\n",
    "    'Members of a religion should be excluded and marginalized.',\n",
    "    'Members of a religion should remain in their respective countries.',\n",
    "    'Members of a religion are compared to animals.',\n",
    "    'A religion or members of a religion are compared to devils or demons.',\n",
    "    'The integration of a religion should be avoided in a country or society.',\n",
    "    'A religion or members of a religion are stupid.',\n",
    "    'A religion is inferior when compared to another religion.',\n",
    "    'A religion is preferred to another.'\n",
    "    'Religious practices of a particular faith should be restricted or banned in public spaces.',\n",
    "    'Religious attire or symbols should be prohibited.',\n",
    "    'A religion promotes violence or intolerance.',\n",
    "    'Members of a religion are a threat.',\n",
    "    'Members of a religion are not trustworthy or loyal.'\n",
    "  ],\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add neutral cases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "source": [
    "def add_rows_to_dataframes(dataframes_dict, new_dataframe):\n",
    "\n",
    "    for key, df in dataframes_dict.items():\n",
    "        # Calculate the maximum number of rows to add\n",
    "        max_rows_to_add = min(len(new_dataframe), len(df))\n",
    "\n",
    "        # Choose random rows from the new dataframe\n",
    "        rows_to_add = new_dataframe.sample(n=max_rows_to_add, replace=True)\n",
    "\n",
    "        rows_to_add = new_dataframe.iloc[:max_rows_to_add]\n",
    "        df = pd.concat([df, rows_to_add], ignore_index=True)\n",
    "        dataframes_dict[key] = df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "add_rows_to_dataframes(test_data, df_neutral)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bart model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "def convert_probabilities_batched(probabilities, label_mapping):\n",
    "    probabilities_list = probabilities.tolist()  # Convert the tensor to a list\n",
    "    return [{name: round(pred * 100, 1) for pred, name in zip(preds, label_mapping)} for preds in probabilities_list]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "def bart_nli_batched_hypotheses(premises, hypotheses):\n",
    "    model_name = 'facebook/bart-large-mnli'\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    model.to(DEVICE) \n",
    "\n",
    "    num_premises = len(premises)\n",
    "    num_hypotheses = len(hypotheses)\n",
    "    results = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_premises):\n",
    "            labels = []\n",
    "\n",
    "            # Tokenize the input pair\n",
    "            inputs = tokenizer([premises[i]] * num_hypotheses, hypotheses, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "            # Run the input through the model\n",
    "            logits = model(**inputs.to(DEVICE)).logits\n",
    "\n",
    "            # Get probabilities and labels for the input\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            label_mapping = ['contradiction', 'neutral', 'entailment']\n",
    "            labels = [label_mapping[p.argmax().item()] for p in probabilities]\n",
    "\n",
    "            results[premises[i]] = (labels, convert_probabilities_batched(probabilities, label_mapping))\n",
    "    return results\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run data through model, add labels and probabilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "source": [
    "def run_bart_model_add_labels(category):\n",
    "    # Create a copy of the input dataframe\n",
    "    df_copy = test_data[category].copy()\n",
    "\n",
    "    # Run BART NLI on the dataframes for the specified category\n",
    "    results = bart_nli_batched_hypotheses(list(df_copy['comment_text']), hypotheses[category])\n",
    "\n",
    "    # Process the results separately and add them to the dataframe\n",
    "    labels_column = []\n",
    "    probabilities_column = []\n",
    "\n",
    "    for premise in df_copy['comment_text']:\n",
    "        if premise in results:\n",
    "            labels, probabilities = results[premise]\n",
    "        else:\n",
    "            labels, probabilities = None, None\n",
    "        labels_column.append(labels)\n",
    "        probabilities_column.append(probabilities)\n",
    "\n",
    "    df_copy['labels'] = labels_column\n",
    "    df_copy['probabilities'] = probabilities_column\n",
    "\n",
    "    return df_copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_results = run_bart_model_add_labels('political')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate f1 scores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "source": [
    "def determine_label_accuracy(df, total_checked=len(hypotheses['race'])):\n",
    "    def is_correct_bias(row, n_labels):\n",
    "        labels = ast.literal_eval(row['labels'])\n",
    "        return sum(label == 'entailment' for label in labels) >= n_labels\n",
    "\n",
    "    def is_correct_neutral(row):\n",
    "        labels = ast.literal_eval(row['labels'])\n",
    "        return all(label != 'entailment' for label in labels)\n",
    "\n",
    "    # Initialize a list to store the boolean results for each row\n",
    "    label_correctness_list = []\n",
    "\n",
    "    # Iterate over each row\n",
    "    for _, row in df.iterrows():\n",
    "        # Initialize a list to store the results for this row\n",
    "        row_results = []\n",
    "        # Iterate from 1 to n (inclusive) to calculate is_label_correct for this row\n",
    "        for n in range(1, total_checked + 1):\n",
    "            result = is_correct_bias(row, n) if row['bias'] == 'bias' else is_correct_neutral(row)\n",
    "            row_results.append(result)\n",
    "        # Append the row results to the main list\n",
    "        label_correctness_list.append(row_results)\n",
    "\n",
    "    # Add the list as the 'is_label_correct' column in the DataFrame\n",
    "    df['is_label_correct'] = pd.Series(label_correctness_list)\n",
    "\n",
    "    df['predicted'] = True\n",
    "    return df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "df_results = determine_label_accuracy(df_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/yy/fwc73zl141q0zj_v307n1l9w0000gn/T/ipykernel_91610/3546598877.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df['is_label_correct'] = pd.Series(label_correctness_dict)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to calculate and print F1 score for a given DataFrame\n",
    "def print_f1_score(df, category_name):\n",
    "    f1 = f1_score(df['is_label_correct'], df['predicted'])\n",
    "    print(f\"F1 score for {category_name}: {f1}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "source": [
    "# Read the CSV files into DataFrames\n",
    "df_political_results = pd.read_csv('./results/final/political_results.csv')\n",
    "df_gender_results = pd.read_csv('./results/final/gender_results.csv')\n",
    "df_lgbtq_results = pd.read_csv('./results/final/lgbtq_results.csv')\n",
    "df_race_results = pd.read_csv('./results/final/race_results.csv')\n",
    "df_religion_results = pd.read_csv('./results/final/religion_results.csv')\n",
    "\n",
    "df_political_results.drop('is_label_correct', axis=1, inplace=True)\n",
    "df_gender_results.drop('is_label_correct', axis=1, inplace=True)\n",
    "df_lgbtq_results.drop('is_label_correct', axis=1, inplace=True)\n",
    "df_race_results.drop('is_label_correct', axis=1, inplace=True)\n",
    "df_religion_results.drop('is_label_correct', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "source": [
    "df_gender_results = determine_label_accuracy(df_gender_results, 15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "source": [
    "# Combine the DataFrames vertically\n",
    "combined_df = pd.concat([df_political_results, df_gender_results, df_lgbtq_results, df_race_results, df_religion_results], ignore_index=True)\n",
    "\n",
    "combined_results = './results/final/combined_results.csv'\n",
    "combined_df.to_csv(combined_results, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "source": [
    "print_f1_score(combined_df, 'Combined')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score for Combined: 0.8153684210526316\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "source": [
    "df_gender_results.sample(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>identity_attack_x</th>\n",
       "      <th>bias</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>rationale</th>\n",
       "      <th>labels</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>predicted</th>\n",
       "      <th>is_label_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>Yessireee bobbereno Mighty fine move. Mighty fine About fricken time. And white folks are jonesing again and again and again. Always jonesing. You cant have what you had for thousands and thousands of years because I cant have it even if I never did. Hello? Get a life</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'neutral', 'entailment', 'contradiction', 'entailment']</td>\n",
       "      <td>[{'contradiction': 90.1, 'neutral': 6.7, 'entailment': 3.2}, {'contradiction': 92.6, 'neutral': 7.1, 'entailment': 0.3}, {'contradiction': 67.4, 'neutral': 17.5, 'entailment': 15.1}, {'contradiction': 38.4, 'neutral': 56.5, 'entailment': 5.0}, {'contradiction': 64.4, 'neutral': 23.0, 'entailment': 12.6}, {'contradiction': 57.8, 'neutral': 29.4, 'entailment': 12.8}, {'contradiction': 49.9, 'neutral': 28.1, 'entailment': 22.0}, {'contradiction': 14.3, 'neutral': 25.9, 'entailment': 59.8}, {'co...</td>\n",
       "      <td>True</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>323</td>\n",
       "      <td>Would not an ultimate racist be a disturbed halfwhite man who longs to be black because his absent father was black and dislikes a majority white country.</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']</td>\n",
       "      <td>[{'contradiction': 81.8, 'neutral': 12.2, 'entailment': 6.0}, {'contradiction': 75.1, 'neutral': 14.0, 'entailment': 10.9}, {'contradiction': 52.4, 'neutral': 23.8, 'entailment': 23.8}, {'contradiction': 84.0, 'neutral': 14.7, 'entailment': 1.3}, {'contradiction': 76.0, 'neutral': 14.8, 'entailment': 9.2}, {'contradiction': 62.6, 'neutral': 12.7, 'entailment': 24.6}, {'contradiction': 65.7, 'neutral': 32.4, 'entailment': 1.9}, {'contradiction': 53.6, 'neutral': 29.6, 'entailment': 16.8}, {'c...</td>\n",
       "      <td>True</td>\n",
       "      <td>[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>Trump is showing a little too much here.  He is called a racist bigot and much worse by higher profile people than an ESPN host.  Yet where is the outrage towards them?  Oooohhhh this just happens to be a black female.  Aaaahhhh... OK.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>bias</td>\n",
       "      <td>blacks,women</td>\n",
       "      <td>race,gender</td>\n",
       "      <td>prejudice towards black women</td>\n",
       "      <td>['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']</td>\n",
       "      <td>[{'contradiction': 83.1, 'neutral': 14.4, 'entailment': 2.5}, {'contradiction': 95.1, 'neutral': 4.6, 'entailment': 0.3}, {'contradiction': 80.8, 'neutral': 10.6, 'entailment': 8.5}, {'contradiction': 57.7, 'neutral': 38.9, 'entailment': 3.4}, {'contradiction': 76.4, 'neutral': 14.6, 'entailment': 9.0}, {'contradiction': 87.3, 'neutral': 8.3, 'entailment': 4.4}, {'contradiction': 14.1, 'neutral': 74.8, 'entailment': 11.1}, {'contradiction': 43.7, 'neutral': 39.7, 'entailment': 16.5}, {'contr...</td>\n",
       "      <td>True</td>\n",
       "      <td>[True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Show me any Imam that says homosexuals women and Atheists are equal to Muslim men...and Ill show you an Imam with a Fatwa on him...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>bias</td>\n",
       "      <td>muslims,homosexuals,women,atheists</td>\n",
       "      <td>religion,lgbtq,gender</td>\n",
       "      <td>prejudice against muslims,homosexuals,women,atheists</td>\n",
       "      <td>['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']</td>\n",
       "      <td>[{'contradiction': 70.5, 'neutral': 26.9, 'entailment': 2.6}, {'contradiction': 73.9, 'neutral': 24.1, 'entailment': 1.9}, {'contradiction': 76.7, 'neutral': 18.0, 'entailment': 5.2}, {'contradiction': 83.8, 'neutral': 14.2, 'entailment': 1.9}, {'contradiction': 55.3, 'neutral': 32.1, 'entailment': 12.6}, {'contradiction': 58.3, 'neutral': 30.8, 'entailment': 10.9}, {'contradiction': 62.1, 'neutral': 37.0, 'entailment': 0.9}, {'contradiction': 22.6, 'neutral': 49.1, 'entailment': 28.3}, {'co...</td>\n",
       "      <td>True</td>\n",
       "      <td>[True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>Own it Bill. You simply agree with those types of speech. But dont worry the whole damned country is set up to protect white male privilege. Thats the problem to white dudes any hint of equality feels like oppression.</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>bias</td>\n",
       "      <td>whites,men</td>\n",
       "      <td>race,gender</td>\n",
       "      <td>prejudice against white men</td>\n",
       "      <td>['contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction']</td>\n",
       "      <td>[{'contradiction': 89.8, 'neutral': 8.7, 'entailment': 1.4}, {'contradiction': 95.9, 'neutral': 4.0, 'entailment': 0.1}, {'contradiction': 84.3, 'neutral': 14.2, 'entailment': 1.5}, {'contradiction': 30.7, 'neutral': 68.8, 'entailment': 0.5}, {'contradiction': 72.3, 'neutral': 24.8, 'entailment': 3.0}, {'contradiction': 88.2, 'neutral': 8.3, 'entailment': 3.5}, {'contradiction': 85.9, 'neutral': 13.4, 'entailment': 0.7}, {'contradiction': 10.7, 'neutral': 68.1, 'entailment': 21.2}, {'contrad...</td>\n",
       "      <td>True</td>\n",
       "      <td>[True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  \\\n",
       "455         455   \n",
       "323         323   \n",
       "75           75   \n",
       "47           47   \n",
       "114         114   \n",
       "\n",
       "                                                                                                                                                                                                                                                                     comment_text  \\\n",
       "455  Yessireee bobbereno Mighty fine move. Mighty fine About fricken time. And white folks are jonesing again and again and again. Always jonesing. You cant have what you had for thousands and thousands of years because I cant have it even if I never did. Hello? Get a life   \n",
       "323                                                                                                                    Would not an ultimate racist be a disturbed halfwhite man who longs to be black because his absent father was black and dislikes a majority white country.   \n",
       "75                                    Trump is showing a little too much here.  He is called a racist bigot and much worse by higher profile people than an ESPN host.  Yet where is the outrage towards them?  Oooohhhh this just happens to be a black female.  Aaaahhhh... OK.   \n",
       "47                                                                                                                                            Show me any Imam that says homosexuals women and Atheists are equal to Muslim men...and Ill show you an Imam with a Fatwa on him...   \n",
       "114                                                     Own it Bill. You simply agree with those types of speech. But dont worry the whole damned country is set up to protect white male privilege. Thats the problem to white dudes any hint of equality feels like oppression.   \n",
       "\n",
       "     identity_attack_x     bias                              target  \\\n",
       "455           0.257143  neutral                                 NaN   \n",
       "323           0.533333  neutral                                 NaN   \n",
       "75            0.500000     bias                        blacks,women   \n",
       "47            0.800000     bias  muslims,homosexuals,women,atheists   \n",
       "114           0.500000     bias                          whites,men   \n",
       "\n",
       "                  category  \\\n",
       "455                   none   \n",
       "323                   none   \n",
       "75             race,gender   \n",
       "47   religion,lgbtq,gender   \n",
       "114            race,gender   \n",
       "\n",
       "                                                rationale  \\\n",
       "455                                                   NaN   \n",
       "323                                                   NaN   \n",
       "75                          prejudice towards black women   \n",
       "47   prejudice against muslims,homosexuals,women,atheists   \n",
       "114                           prejudice against white men   \n",
       "\n",
       "                                                                                                                                                                                                                                                        labels  \\\n",
       "455                    ['contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'neutral', 'entailment', 'contradiction', 'entailment']   \n",
       "323  ['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']   \n",
       "75         ['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']   \n",
       "47         ['contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment']   \n",
       "114              ['contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           probabilities  \\\n",
       "455  [{'contradiction': 90.1, 'neutral': 6.7, 'entailment': 3.2}, {'contradiction': 92.6, 'neutral': 7.1, 'entailment': 0.3}, {'contradiction': 67.4, 'neutral': 17.5, 'entailment': 15.1}, {'contradiction': 38.4, 'neutral': 56.5, 'entailment': 5.0}, {'contradiction': 64.4, 'neutral': 23.0, 'entailment': 12.6}, {'contradiction': 57.8, 'neutral': 29.4, 'entailment': 12.8}, {'contradiction': 49.9, 'neutral': 28.1, 'entailment': 22.0}, {'contradiction': 14.3, 'neutral': 25.9, 'entailment': 59.8}, {'co...   \n",
       "323  [{'contradiction': 81.8, 'neutral': 12.2, 'entailment': 6.0}, {'contradiction': 75.1, 'neutral': 14.0, 'entailment': 10.9}, {'contradiction': 52.4, 'neutral': 23.8, 'entailment': 23.8}, {'contradiction': 84.0, 'neutral': 14.7, 'entailment': 1.3}, {'contradiction': 76.0, 'neutral': 14.8, 'entailment': 9.2}, {'contradiction': 62.6, 'neutral': 12.7, 'entailment': 24.6}, {'contradiction': 65.7, 'neutral': 32.4, 'entailment': 1.9}, {'contradiction': 53.6, 'neutral': 29.6, 'entailment': 16.8}, {'c...   \n",
       "75   [{'contradiction': 83.1, 'neutral': 14.4, 'entailment': 2.5}, {'contradiction': 95.1, 'neutral': 4.6, 'entailment': 0.3}, {'contradiction': 80.8, 'neutral': 10.6, 'entailment': 8.5}, {'contradiction': 57.7, 'neutral': 38.9, 'entailment': 3.4}, {'contradiction': 76.4, 'neutral': 14.6, 'entailment': 9.0}, {'contradiction': 87.3, 'neutral': 8.3, 'entailment': 4.4}, {'contradiction': 14.1, 'neutral': 74.8, 'entailment': 11.1}, {'contradiction': 43.7, 'neutral': 39.7, 'entailment': 16.5}, {'contr...   \n",
       "47   [{'contradiction': 70.5, 'neutral': 26.9, 'entailment': 2.6}, {'contradiction': 73.9, 'neutral': 24.1, 'entailment': 1.9}, {'contradiction': 76.7, 'neutral': 18.0, 'entailment': 5.2}, {'contradiction': 83.8, 'neutral': 14.2, 'entailment': 1.9}, {'contradiction': 55.3, 'neutral': 32.1, 'entailment': 12.6}, {'contradiction': 58.3, 'neutral': 30.8, 'entailment': 10.9}, {'contradiction': 62.1, 'neutral': 37.0, 'entailment': 0.9}, {'contradiction': 22.6, 'neutral': 49.1, 'entailment': 28.3}, {'co...   \n",
       "114  [{'contradiction': 89.8, 'neutral': 8.7, 'entailment': 1.4}, {'contradiction': 95.9, 'neutral': 4.0, 'entailment': 0.1}, {'contradiction': 84.3, 'neutral': 14.2, 'entailment': 1.5}, {'contradiction': 30.7, 'neutral': 68.8, 'entailment': 0.5}, {'contradiction': 72.3, 'neutral': 24.8, 'entailment': 3.0}, {'contradiction': 88.2, 'neutral': 8.3, 'entailment': 3.5}, {'contradiction': 85.9, 'neutral': 13.4, 'entailment': 0.7}, {'contradiction': 10.7, 'neutral': 68.1, 'entailment': 21.2}, {'contrad...   \n",
       "\n",
       "     predicted  \\\n",
       "455       True   \n",
       "323       True   \n",
       "75        True   \n",
       "47        True   \n",
       "114       True   \n",
       "\n",
       "                                                                                              is_label_correct  \n",
       "455  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]  \n",
       "323  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]  \n",
       "75     [True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]  \n",
       "47     [True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]  \n",
       "114    [True, True, False, False, False, False, False, False, False, False, False, False, False, False, False]  "
      ]
     },
     "metadata": {},
     "execution_count": 392
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}